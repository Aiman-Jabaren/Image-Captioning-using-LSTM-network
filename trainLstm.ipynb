{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[nltk_data] Downloading package punkt to /home/srajguru/nltk_data...\n",
      "[nltk_data]   Package punkt is already up-to-date!\n"
     ]
    }
   ],
   "source": [
    "from decoder_new import *\n",
    "from encoder import *\n",
    "from data_loader import *\n",
    "import pickle\n",
    "import random\n",
    "import torch.optim as optim\n",
    "from torch.autograd import Variable\n",
    "import csv\n",
    "import time\n",
    "from tqdm import tqdm\n",
    "import gc\n",
    "import os\n",
    "import torchvision.transforms as transforms"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "def trainEncoderDecoder(encoder, decoder, criterion, epochs,\n",
    "                        train_loader,val_loader, test_loader, name, batch_size, maxSeqLen, vocablen):\n",
    "    \n",
    "    #Create non-existing logfiles\n",
    "    logname = './logs/' + name + '.log'\n",
    "    i = 0\n",
    "    if os.path.exists(logname) == True:\n",
    "        \n",
    "        logname = './logs/' + name + str(i) + '.log'\n",
    "        while os.path.exists(logname):\n",
    "            i+=1\n",
    "            logname = './logs/' + name + str(i) + '.log'\n",
    "\n",
    "    print('Loading results to logfile: ' + logname)\n",
    "    with open(logname, \"w\") as file:\n",
    "        file.write(\"Log file DATA: Validation Loss and Accuracy\\n\") \n",
    "    \n",
    "    logname_summary = './logs/' + name + '_summary' + str(i) + '.log'    \n",
    "    print('Loading Summary to : ' + logname_summary) \n",
    "    \n",
    "    parameters = list(encoder.parameters())\n",
    "    parameters.extend(list(decoder.parameters()))\n",
    "    optimizer = optim.Adam(parameters, lr=5e-3)\n",
    "    use_gpu = torch.cuda.is_available()\n",
    "    if use_gpu:\n",
    "        device = torch.device(\"cuda:0\")\n",
    "#         encoder = torch.nn.DataParallel(encoder)\n",
    "#         decoder = torch.nn.DataParallel(decoder)\n",
    "        \n",
    "        encoder.to(device)\n",
    "        decoder.to(device)\n",
    "        \n",
    "        \n",
    "    \n",
    "    val_loss_set = []\n",
    "    val_acc_set = []\n",
    "    val_iou_set = []\n",
    "    \n",
    "    \n",
    "    training_loss = []\n",
    "    \n",
    "    # Early Stop criteria\n",
    "    minLoss = 1e6\n",
    "    minLossIdx = 0\n",
    "    earliestStopEpoch = 10\n",
    "    earlyStopDelta = 5\n",
    "    for epoch in range(epochs):\n",
    "        ts = time.time()\n",
    "\n",
    "        #import pdb; pdb.set_trace()                     \n",
    "        for iter, (inputs, labels, lengths, actual_lengths) in tqdm(enumerate(train_loader)):\n",
    "            print('inp shape: ', inputs.shape)\n",
    "#             print(\"Inputs:\")\n",
    "#             print(inputs)\n",
    "            \n",
    "            print(\"Labels\")\n",
    "            print(labels)\n",
    "            print('labels shape: ', labels.shape)\n",
    "            print(\"lengths: \", lengths)\n",
    "            print(\"lengths shape: \", len(lengths))\n",
    "            print(\"actual_lengths: \", actual_lengths)\n",
    "            print(\"actual_lengths shape: \", len(actual_lengths))\n",
    "            optimizer.zero_grad()\n",
    "            \n",
    "            \n",
    "            if use_gpu:\n",
    "                inputs = inputs.to(device)# Move your inputs onto the gpu\n",
    "                labels = labels.to(device) # Move your labels onto the gpu\n",
    "            \n",
    "                \n",
    "#             outputs = model(inputs)\n",
    "            enc_out = encoder(inputs)\n",
    "            print('enc out shape: ', enc_out.size())\n",
    "        \n",
    "            temperature = 1\n",
    "            test_pred = decoder.generate_caption(enc_out, maxSeqLen, temperature)\n",
    "            for b in range(batch_size):\n",
    "                flag = False\n",
    "                for wi in range(maxSeqLen):\n",
    "                    if test_pred[b, wi] == 2:\n",
    "                        flag = True\n",
    "                    if flag:\n",
    "                        test_pred[b, wi] = 0\n",
    "            print('test pred: ', test_pred)\n",
    "            print('test pred shape: ', test_pred.size())\n",
    "        \n",
    "            outputs = decoder(labels, enc_out, actual_lengths)\n",
    "            print('outputs shape: ', outputs.size())\n",
    "            new_outputs = torch.zeros(batch_size, maxSeqLen, vocablen)\n",
    "            for dim in range(maxSeqLen):\n",
    "                for b in range(batch_size):\n",
    "                    new_outputs[b, dim, 0] = 1.0\n",
    "            new_outputs[:, :(outputs.shape[1]), :] = outputs\n",
    "            new_outputs = new_outputs.permute(0, 2, 1).to(device)\n",
    "            #del inputs\n",
    "            loss = criterion(new_outputs, Variable(labels.long()))\n",
    "            del labels\n",
    "            del outputs\n",
    "\n",
    "            loss.backward()\n",
    "            loss = loss#.item()\n",
    "            optimizer.step()\n",
    "\n",
    "            if iter % 1 == 0:\n",
    "                print(\"epoch{}, iter{}, loss: {}\".format(epoch, iter, loss))\n",
    "\n",
    "        \n",
    "        # calculate val loss each epoch\n",
    "#         val_loss, val_acc, val_iou = val(model, val_loader, criterion, use_gpu)\n",
    "#         val_loss_set.append(val_loss)\n",
    "#         val_acc_set.append(val_acc)\n",
    "#         val_iou_set.append(val_iou)\n",
    "        \n",
    "#         print(\"epoch {}, time {}, train loss {}, val loss {}, val acc {}, val iou {}\".format(epoch, time.time() - ts,\n",
    "#                                                                                                loss, val_loss,\n",
    "#                                                                                                val_acc,\n",
    "#                                                                                                val_iou))        \n",
    "        training_loss.append(loss)\n",
    "        \n",
    "        with open(logname, \"a\") as file:\n",
    "            file.write(\"writing!\\n\")\n",
    "            file.write(\"Finish epoch {}, time elapsed {}\".format(epoch, time.time() - ts))\n",
    "            file.write(\"\\n training Loss:   \" + str(loss.item()))\n",
    "#             file.write(\"\\n Validation Loss: \" + str(val_loss_set[-1]))\n",
    "#             file.write(\"\\n Validation acc:  \" + str(val_acc_set[-1]))\n",
    "#             file.write(\"\\n Validation iou:  \" + str(val_iou_set[-1]) + \"\\n \")                                             \n",
    "                                                                                                \n",
    "                                                                                                \n",
    "        \n",
    "        # Early stopping\n",
    "#         if val_loss < minLoss:\n",
    "#             # Store new best\n",
    "#             torch.save(model, name)\n",
    "#             minLoss = val_loss#.item()\n",
    "#             minLossIdx = epoch\n",
    "            \n",
    "        # If passed min threshold, and no new min has been reached for delta epochs\n",
    "#         elif epoch > earliestStopEpoch and (epoch - minLossIdx) > earlyStopDelta:\n",
    "#             print(\"Stopping early at {}\".format(minLossIdx))\n",
    "#             break\n",
    "        \n",
    "\n",
    "        \n",
    "        \n",
    "    with open(logname_summary, \"a\") as file:\n",
    "            file.write(\"Summary!\\n\")\n",
    "            file.write(\"Stopped early at {}\".format(minLossIdx))\n",
    "            file.write(\"\\n training Loss:   \" + str(training_loss))        \n",
    "            file.write(\"\\n Validation Loss: \" + str(val_loss_set))\n",
    "            file.write(\"\\n Validation acc:  \" + str(val_acc_set))\n",
    "            file.write(\"\\n Validation iou:  \" + str(val_iou_set) + \"\\n \")\n",
    "            \n",
    "        \n",
    "    #return val_loss_set, val_acc_set, val_iou_set"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "loading annotations into memory...\n",
      "Done (t=0.93s)\n",
      "creating index...\n",
      "index created!\n",
      "Loading results to logfile: ./logs/LSTM77.log\n",
      "Loading Summary to : ./logs/LSTM_summary77.log\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "1it [00:00,  3.05it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "inp shape:  torch.Size([4, 3, 480, 640])\n",
      "Labels\n",
      "tensor([[  1,   4,  81,  14, 723, 225,  40,   4, 133,  80,  33, 279,  19,   2,\n",
      "           0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,\n",
      "           0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,\n",
      "           0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0],\n",
      "        [  1,   4,  81,  14, 455, 225,  40,   4, 133,  80,  33, 279,   2,   0,\n",
      "           0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,\n",
      "           0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,\n",
      "           0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0],\n",
      "        [  1,   4, 331,  14,  52,  77,  40,   4, 265, 133,   2,   0,   0,   0,\n",
      "           0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,\n",
      "           0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,\n",
      "           0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0],\n",
      "        [  1,   4,  81,  14,  52,  53, 225,  40,   4, 133, 286, 112,  33, 279,\n",
      "          19,   2,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,\n",
      "           0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,\n",
      "           0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0]])\n",
      "labels shape:  torch.Size([4, 54])\n",
      "lengths:  [54, 54, 54, 54]\n",
      "lengths shape:  4\n",
      "actual_lengths:  (14, 13, 11, 16)\n",
      "actual_lengths shape:  4\n",
      "enc out shape:  torch.Size([4, 10])\n",
      "word ids:  tensor([[7040,  610, 6112,  992,  809, 4219, 9536, 3540, 3716,  699, 8078,  790,\n",
      "          133, 2494, 1160, 6417, 2522, 5373, 3716,  699, 8078,  790,  133, 2494,\n",
      "         1160, 6417, 2522, 5373, 3716,  699, 8078,  790,  133, 2494, 1160, 6417,\n",
      "         2522, 5373, 3716,  699, 8078,  790,  133, 2494, 1160, 6417, 2522, 5373,\n",
      "         3716,  699, 8078,  790,  133, 2494],\n",
      "        [7040,  610, 6112,  992,  809, 4219, 9536, 3540, 3716,  699, 8078,  790,\n",
      "          133, 2494, 1160, 6417, 2522, 5373, 3716,  699, 8078,  790,  133, 2494,\n",
      "         1160, 6417, 2522, 5373, 3716,  699, 8078,  790,  133, 2494, 1160, 6417,\n",
      "         2522, 5373, 3716,  699, 8078,  790,  133, 2494, 1160, 6417, 2522, 5373,\n",
      "         3716,  699, 8078,  790,  133, 2494],\n",
      "        [7040,  610, 6112,  992,  809, 4219, 9536, 3540, 3716,  699, 8078,  790,\n",
      "          133, 2494, 1160, 6417, 2522, 5373, 3716,  699, 8078,  790,  133, 2494,\n",
      "         1160, 6417, 2522, 5373, 3716,  699, 8078,  790,  133, 2494, 1160, 6417,\n",
      "         2522, 5373, 3716,  699, 8078,  790,  133, 2494, 1160, 6417, 2522, 5373,\n",
      "         3716,  699, 8078,  790,  133, 2494],\n",
      "        [7040,  610, 6112,  992,  809, 4219, 9536, 3540, 3716,  699, 8078,  790,\n",
      "          133, 2494, 1160, 6417, 2522, 5373, 3716,  699, 8078,  790,  133, 2494,\n",
      "         1160, 6417, 2522, 5373, 3716,  699, 8078,  790,  133, 2494, 1160, 6417,\n",
      "         2522, 5373, 3716,  699, 8078,  790,  133, 2494, 1160, 6417, 2522, 5373,\n",
      "         3716,  699, 8078,  790,  133, 2494]], device='cuda:0')\n",
      "test pred:  tensor([[7040,  610, 6112,  992,  809, 4219, 9536, 3540, 3716,  699, 8078,  790,\n",
      "          133, 2494, 1160, 6417, 2522, 5373, 3716,  699, 8078,  790,  133, 2494,\n",
      "         1160, 6417, 2522, 5373, 3716,  699, 8078,  790,  133, 2494, 1160, 6417,\n",
      "         2522, 5373, 3716,  699, 8078,  790,  133, 2494, 1160, 6417, 2522, 5373,\n",
      "         3716,  699, 8078,  790,  133, 2494],\n",
      "        [7040,  610, 6112,  992,  809, 4219, 9536, 3540, 3716,  699, 8078,  790,\n",
      "          133, 2494, 1160, 6417, 2522, 5373, 3716,  699, 8078,  790,  133, 2494,\n",
      "         1160, 6417, 2522, 5373, 3716,  699, 8078,  790,  133, 2494, 1160, 6417,\n",
      "         2522, 5373, 3716,  699, 8078,  790,  133, 2494, 1160, 6417, 2522, 5373,\n",
      "         3716,  699, 8078,  790,  133, 2494],\n",
      "        [7040,  610, 6112,  992,  809, 4219, 9536, 3540, 3716,  699, 8078,  790,\n",
      "          133, 2494, 1160, 6417, 2522, 5373, 3716,  699, 8078,  790,  133, 2494,\n",
      "         1160, 6417, 2522, 5373, 3716,  699, 8078,  790,  133, 2494, 1160, 6417,\n",
      "         2522, 5373, 3716,  699, 8078,  790,  133, 2494, 1160, 6417, 2522, 5373,\n",
      "         3716,  699, 8078,  790,  133, 2494],\n",
      "        [7040,  610, 6112,  992,  809, 4219, 9536, 3540, 3716,  699, 8078,  790,\n",
      "          133, 2494, 1160, 6417, 2522, 5373, 3716,  699, 8078,  790,  133, 2494,\n",
      "         1160, 6417, 2522, 5373, 3716,  699, 8078,  790,  133, 2494, 1160, 6417,\n",
      "         2522, 5373, 3716,  699, 8078,  790,  133, 2494, 1160, 6417, 2522, 5373,\n",
      "         3716,  699, 8078,  790,  133, 2494]], device='cuda:0')\n",
      "test pred shape:  torch.Size([4, 54])\n",
      "sentence shape:  torch.Size([4, 54])\n",
      "features size:  torch.Size([4, 10])\n",
      "embeds size:  torch.Size([4, 54, 10])\n",
      "lengths:  (14, 13, 11, 16)\n",
      "lstm inp shape:  torch.Size([4, 55, 10])\n",
      "temp shape:  torch.Size([4, 16, 50])\n",
      "fc_out shape:  torch.Size([4, 16, 9956])\n",
      "outputs shape:  torch.Size([4, 16, 9956])\n",
      "epoch0, iter0, loss: -0.7037349343299866\n"
     ]
    },
    {
     "ename": "RuntimeError",
     "evalue": "Caught RuntimeError in DataLoader worker process 0.\nOriginal Traceback (most recent call last):\n  File \"/opt/conda/lib/python3.7/site-packages/torch/utils/data/_utils/worker.py\", line 178, in _worker_loop\n    data = fetcher.fetch(index)\n  File \"/opt/conda/lib/python3.7/site-packages/torch/utils/data/_utils/fetch.py\", line 47, in fetch\n    return self.collate_fn(data)\n  File \"/home/srajguru/Image-Captioning-using-LSTM-network/data_loader.py\", line 99, in collate_fn\n    images = torch.stack(images, 0)\nRuntimeError: invalid argument 0: Sizes of tensors must match except in dimension 0. Got 480 and 500 in dimension 2 at /opt/conda/conda-bld/pytorch_1573049310284/work/aten/src/TH/generic/THTensor.cpp:689\n",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mRuntimeError\u001b[0m                              Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-3-7fd16642653d>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m     57\u001b[0m     \u001b[0mepochs\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;36m100\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     58\u001b[0m     trainEncoderDecoder(encoder, decoder, criterion, epochs, \n\u001b[0;32m---> 59\u001b[0;31m                         trainDl, trainDl, trainDl, \"LSTM\", batch_size, 54, vocab.idx)\n\u001b[0m\u001b[1;32m     60\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     61\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m<ipython-input-2-190ae9ad1aaa>\u001b[0m in \u001b[0;36mtrainEncoderDecoder\u001b[0;34m(encoder, decoder, criterion, epochs, train_loader, val_loader, test_loader, name, batch_size, maxSeqLen, vocablen)\u001b[0m\n\u001b[1;32m     49\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     50\u001b[0m         \u001b[0;31m#import pdb; pdb.set_trace()\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 51\u001b[0;31m         \u001b[0;32mfor\u001b[0m \u001b[0miter\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m(\u001b[0m\u001b[0minputs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mlabels\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mlengths\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mactual_lengths\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mtqdm\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0menumerate\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtrain_loader\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     52\u001b[0m             \u001b[0mprint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m'inp shape: '\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0minputs\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mshape\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     53\u001b[0m \u001b[0;31m#             print(\"Inputs:\")\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/opt/conda/lib/python3.7/site-packages/tqdm/_tqdm.py\u001b[0m in \u001b[0;36m__iter__\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m   1015\u001b[0m                 \"\"\"), fp_write=getattr(self.fp, 'write', sys.stderr.write))\n\u001b[1;32m   1016\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1017\u001b[0;31m             \u001b[0;32mfor\u001b[0m \u001b[0mobj\u001b[0m \u001b[0;32min\u001b[0m \u001b[0miterable\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1018\u001b[0m                 \u001b[0;32myield\u001b[0m \u001b[0mobj\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1019\u001b[0m                 \u001b[0;31m# Update and possibly print the progressbar.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/opt/conda/lib/python3.7/site-packages/torch/utils/data/dataloader.py\u001b[0m in \u001b[0;36m__next__\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m    817\u001b[0m             \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    818\u001b[0m                 \u001b[0;32mdel\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_task_info\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0midx\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 819\u001b[0;31m                 \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_process_data\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdata\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    820\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    821\u001b[0m     \u001b[0mnext\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0m__next__\u001b[0m  \u001b[0;31m# Python 2 compatibility\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/opt/conda/lib/python3.7/site-packages/torch/utils/data/dataloader.py\u001b[0m in \u001b[0;36m_process_data\u001b[0;34m(self, data)\u001b[0m\n\u001b[1;32m    844\u001b[0m         \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_try_put_index\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    845\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0misinstance\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdata\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mExceptionWrapper\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 846\u001b[0;31m             \u001b[0mdata\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mreraise\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    847\u001b[0m         \u001b[0;32mreturn\u001b[0m \u001b[0mdata\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    848\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/opt/conda/lib/python3.7/site-packages/torch/_utils.py\u001b[0m in \u001b[0;36mreraise\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m    383\u001b[0m             \u001b[0;31m# (https://bugs.python.org/issue2651), so we work around it.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    384\u001b[0m             \u001b[0mmsg\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mKeyErrorMessage\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mmsg\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 385\u001b[0;31m         \u001b[0;32mraise\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mexc_type\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mmsg\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[0;31mRuntimeError\u001b[0m: Caught RuntimeError in DataLoader worker process 0.\nOriginal Traceback (most recent call last):\n  File \"/opt/conda/lib/python3.7/site-packages/torch/utils/data/_utils/worker.py\", line 178, in _worker_loop\n    data = fetcher.fetch(index)\n  File \"/opt/conda/lib/python3.7/site-packages/torch/utils/data/_utils/fetch.py\", line 47, in fetch\n    return self.collate_fn(data)\n  File \"/home/srajguru/Image-Captioning-using-LSTM-network/data_loader.py\", line 99, in collate_fn\n    images = torch.stack(images, 0)\nRuntimeError: invalid argument 0: Sizes of tensors must match except in dimension 0. Got 480 and 500 in dimension 2 at /opt/conda/conda-bld/pytorch_1573049310284/work/aten/src/TH/generic/THTensor.cpp:689\n"
     ]
    }
   ],
   "source": [
    "if __name__=='__main__':\n",
    "    with open('TrainImageIds.csv', 'r') as f:\n",
    "        reader = csv.reader(f)\n",
    "        trainIds = list(reader)[0]\n",
    "        \n",
    "#     with open('TestImageIds.csv', 'r') as f:\n",
    "#         reader = csv.reader(f)\n",
    "#         testIds = list(reader)[0]\n",
    "    \n",
    "    trainIds = [int(i) for i in trainIds]\n",
    "    #testIds = [int(i) for i in testIds[0]]\n",
    "    \n",
    "    # Will shuffle the trainIds incase of ordering in csv\n",
    "    #random.shuffle(trainIds)\n",
    "    #splitIdx = int(len(trainIds)/5)\n",
    "    \n",
    "    # Selecting 1/5 of training set as validation\n",
    "    #valIds = trainIds[:splitIdx]\n",
    "    #trainIds = trainIds[splitIdx:]\n",
    "    #print(trainIds)\n",
    "    \n",
    "    \n",
    "    trainValRoot = \"./data/images/train/\"\n",
    "    #testRoot = \"./data/images/test/\"\n",
    "    \n",
    "    trainValJson = \"./data/annotations/captions_train2014.json\"\n",
    "    #testJson = \"./data/annotations/captions_val2014.json\"\n",
    "    \n",
    "    \n",
    "    with open('./data/vocab.pkl', 'rb') as f:\n",
    "        vocab = pickle.load(f)\n",
    "    \n",
    "    transform = None\n",
    "    batch_size = 4\n",
    "    shuffle = True\n",
    "    num_workers = 1\n",
    "    \n",
    "    \n",
    "    trainDl = get_loader(trainValRoot, trainValJson, trainIds, vocab, \n",
    "                         transform=transforms.ToTensor(), batch_size=batch_size, \n",
    "                         shuffle=False, num_workers=1)\n",
    "#     valDl = get_loader(trainValRoot, trainValJson, valIds, vocab, \n",
    "#                          transform=None, batch_size=batch_size, \n",
    "#                          shuffle=shuffle, num_workers=1)\n",
    "#    testDl = get_loader(testRoot, testJson, testIds, vocab, \n",
    "#                         transform=None, batch_size=batch_size, \n",
    "#                         shuffle=shuffle, num_workers=1)\n",
    "    \n",
    "    encoded_feature_dim = 10\n",
    "    hidden_dim = 50\n",
    "    \n",
    "    encoder = Encoder(encoded_feature_dim)\n",
    "    decoder = Decoder(encoded_feature_dim, hidden_dim, vocab.idx)\n",
    "    \n",
    "    criterion = nn.NLLLoss()\n",
    "    \n",
    "    epochs = 100\n",
    "    trainEncoderDecoder(encoder, decoder, criterion, epochs, \n",
    "                        trainDl, trainDl, trainDl, \"LSTM\", batch_size, 54, vocab.idx)\n",
    "    \n",
    "    \n",
    "    \n",
    "    \n",
    "    \n",
    "    \n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%debug"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(vocab.word2idx['<start>'])\n",
    "print(vocab.idx2word[0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "trainIds.index(509365)"
   ]
  },
  {
   "cell_type": "raw",
   "metadata": {},
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(trainIds[0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
